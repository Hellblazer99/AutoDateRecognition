{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Column_Classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMMPXHrQdhAwV8hAPe+0lUr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hellblazer99/AutoDateRecognition/blob/main/Column_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-PKXnkoW0Nf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "a91730fd-c279-4562-dd13-5b66a7e36306"
      },
      "source": [
        "!pip install tensorflow==1.2.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/d0/96269b9ecfcc55cb38779831595e0521c34ef4ecdeba08b1ba4194cc4813/tensorflow-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (35.0MB)\n",
            "\u001b[K     |████████████████████████████████| 35.0MB 121kB/s \n",
            "\u001b[?25hCollecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 57.6MB/s \n",
            "\u001b[?25hCollecting backports.weakref==1.0rc1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2.1) (0.35.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2.1) (1.15.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2.1) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2.1) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2.1) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2.1) (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorflow==1.2.1) (49.6.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorflow==1.2.1) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorflow==1.2.1) (3.1.0)\n",
            "Building wheels for collected packages: html5lib\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=d288cbe5ce07ad35479c4885402b0df4c2943722ec0cd596413ea2c383191c48\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "Installing collected packages: html5lib, bleach, backports.weakref, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.5\n",
            "    Uninstalling bleach-3.1.5:\n",
            "      Successfully uninstalled bleach-3.1.5\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 tensorflow-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6ewosqtdMrL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "562ab261-e03b-46d7-dd25-7310d653b078"
      },
      "source": [
        "!pip install keras==2.0.7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/9b/d4a03bf5dcf533fecbbd88053be3a7b4a435e8c2602e5e21a02779dd1aca/Keras-2.0.7-py2.py3-none-any.whl (275kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 7.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 153kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 184kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 194kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 204kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 225kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 235kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 245kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 256kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from keras==2.0.7) (1.0.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.0.7) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras==2.0.7) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano->keras==2.0.7) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano->keras==2.0.7) (1.4.1)\n",
            "\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.0.7 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9WK_j7Tc8m4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "34af72cd-e138-4e12-cabe-3188ce7161d6"
      },
      "source": [
        "!pip install faker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.6/dist-packages (4.1.2)\n",
            "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.6/dist-packages (from faker) (1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.6/dist-packages (from faker) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.4->faker) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWvGZWr7dEGS"
      },
      "source": [
        "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model, Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "import keras.backend as K\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "from faker import Faker\n",
        "from lorem_text import lorem\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from babel.dates import format_date\n",
        "from nmt_utils import *\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67wZnJ7MzzIe"
      },
      "source": [
        "## Creating dataset to be used for model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1E8Wvb_dEgL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5ee1089b-50e8-47b3-cff9-63962c529f48"
      },
      "source": [
        "size = 5000\n",
        "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(size)\n",
        "print(dataset[0])\n",
        "print(human_vocab)\n",
        "print(machine_vocab)\n",
        "print(inv_machine_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [00:00<00:00, 14888.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "('9 may 1998', '1998-05-09')\n",
            "{' ': 0, '.': 1, '/': 2, '0': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, 'a': 13, 'b': 14, 'c': 15, 'd': 16, 'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'w': 33, 'y': 34, '<unk>': 35, '<pad>': 36}\n",
            "{'-': 0, '0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10}\n",
            "{0: '-', 1: '0', 2: '1', 3: '2', 4: '3', 5: '4', 6: '5', 7: '6', 8: '7', 9: '8', 10: '9'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-jUPvULzN8i"
      },
      "source": [
        "dataset_l = [data[0] for data in dataset]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l4zTtfg0GnO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "eee51fa6-cd74-4fae-b96c-a1cc77134cc8"
      },
      "source": [
        "dataset_l[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['9 may 1998',\n",
              " '10.11.19',\n",
              " '9/10/70',\n",
              " 'saturday april 28 1990',\n",
              " 'thursday january 26 1995']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-n8x63wdTbO"
      },
      "source": [
        "num_l = list()\n",
        "for i in range(size):\n",
        "  num_l.append(str(random.randint(-10000, 10000)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlDxSx1yueww",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "365323d6-63a5-48f8-9061-41a0133aa98a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import gutenberg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb-FshoNugvC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fca71fe2-1a9f-474c-ad17-cbacc7511bb1"
      },
      "source": [
        "emma = gutenberg.words('austen-emma.txt')\n",
        "word_l = list(set(emma))[:size]\n",
        "len(word_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZc6mWl4wW1h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1e6861b-12ed-4638-d626-f6ab3bf8cded"
      },
      "source": [
        "emma_sent = gutenberg.sents('austen-emma.txt')\n",
        "sent_l = list(x for x in emma_sent)[:size]\n",
        "len(sent_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1Jkkbn82X49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ab60b49-fab6-47ba-8089-ce204cd47f1a"
      },
      "source": [
        "sent_s = [' '.join(sent) for sent in sent_l]\n",
        "len(sent_s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp8esaWkyTwO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "966ad88d-e16b-4228-99c9-7eaaecfde8a1"
      },
      "source": [
        "op_ls = list()\n",
        "for i in range(0, size):\n",
        "  op_ls.append(1)\n",
        "for i in range(0, size*3):\n",
        "  op_ls.append(0)\n",
        "\n",
        "len(op_ls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmlahb89zFqt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b99a472b-5086-41cf-c615-446e85379944"
      },
      "source": [
        "train_l = dataset_l + num_l + word_l + sent_s\n",
        "len(train_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Vke8ZFxqE0"
      },
      "source": [
        "data_d = {'input': train_l, 'tag': op_ls}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydz2EqMEzv0y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4cb690f7-18fa-4505-db30-668c048fe625"
      },
      "source": [
        "df = pd.DataFrame(data_d)\n",
        "df.iloc[19000, :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "input    It would be the greatest pleasure to them , if...\n",
              "tag                                                      0\n",
              "Name: 19000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gINy9WJ63c1p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ac4ccde0-a52b-42d4-baeb-072d99ef9c03"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9 may 1998</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.11.19</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9/10/70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>saturday april 28 1990</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>thursday january 26 1995</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      input  tag\n",
              "0                9 may 1998    1\n",
              "1                  10.11.19    1\n",
              "2                   9/10/70    1\n",
              "3    saturday april 28 1990    1\n",
              "4  thursday january 26 1995    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQgLtPY-2u34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a8c395e2-299d-414b-9434-a5c3b95c0f03"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>Elton .\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>He had done his duty and could return to his s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>\" When Frank left us ,\" continued he , \" it wa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>It has been completely unexpected .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>That is , _I_ always had a strong persuasion h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   input  tag\n",
              "19995                                           Elton .\"    0\n",
              "19996  He had done his duty and could return to his s...    0\n",
              "19997  \" When Frank left us ,\" continued he , \" it wa...    0\n",
              "19998                It has been completely unexpected .    0\n",
              "19999  That is , _I_ always had a strong persuasion h...    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2T1ZODy1OHW"
      },
      "source": [
        "## Creating date classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4WML-fnfbmB"
      },
      "source": [
        "X = df['input']\n",
        "Y = df['tag']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i0GMWmrlDOP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f215c26a-c595-4cc1-88ae-c83a9ba5b6a8"
      },
      "source": [
        "# The maximum number of words to be used. (most frequent)\n",
        "MAX_NB_WORDS = 50000\n",
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 30\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 25\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(X.values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10627 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WxDABVHjIYi"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvAnrleuci9z"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(X_train)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen = MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRUOhvW9hoGv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eeb7bcb7-c8cd-45e8-ed68-ccf174a3d062"
      },
      "source": [
        "X[4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thursday january 26 1995'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsHQfTveeSD9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "b344710e-b004-46fd-822e-bc7bebfc79f5"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))  \n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 30, 25)            1250000   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 30, 25)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               50400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,300,501\n",
            "Trainable params: 1,300,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v-dzeUqherC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "dd61f33b-593a-4a73-efb5-448f644e7aea"
      },
      "source": [
        "epochs = 5\n",
        "batch_size = 64\n",
        "history = model.fit(sequences_matrix, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15300 samples, validate on 1700 samples\n",
            "Epoch 1/5\n",
            "15300/15300 [==============================] - 29s - loss: 0.0918 - acc: 0.9708 - val_loss: 0.0098 - val_acc: 0.9976\n",
            "Epoch 2/5\n",
            "15300/15300 [==============================] - 29s - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0097 - val_acc: 0.9971\n",
            "Epoch 3/5\n",
            "15300/15300 [==============================] - 29s - loss: 3.6758e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9971\n",
            "Epoch 4/5\n",
            "15300/15300 [==============================] - 29s - loss: 2.6571e-04 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 0.9971\n",
            "Epoch 5/5\n",
            "15300/15300 [==============================] - 29s - loss: 4.2466e-04 - acc: 0.9999 - val_loss: 0.0115 - val_acc: 0.9971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byvbp_23i8uo"
      },
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "test_seq_matrix = sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKjszuX2kZcC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d45395b0-84c0-4dd6-91e9-32edd372c143"
      },
      "source": [
        "accr = model.evaluate(test_seq_matrix, Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000/3000 [==============================] - 1s     \n",
            "Test set\n",
            "  Loss: 0.003\n",
            "  Accuracy: 0.999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYcGlael-Lhe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1034c055-5246-48b8-a757-2bfa76dac652"
      },
      "source": [
        "preds = model.predict_classes(seq_matrix[:5])\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r5/5 [==============================] - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yeFfnMf5tuy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cf3e13a-edfe-41ca-aa42-923074662919"
      },
      "source": [
        "test = random.sample(date_3, 10)\n",
        "seqs = tokenizer.texts_to_sequences(test)\n",
        "seq_matrix = sequence.pad_sequences(seqs, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "preds = model.predict_classes(seq_matrix)\n",
        "preds = preds.tolist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r10/10 [==============================] - 0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USny04Wnbm_L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dcd2688-2a34-4977-f1b3-8abc5055a3c7"
      },
      "source": [
        "preds.count([1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT1WMdVUldTE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "acf331e8-8e09-41d2-9613-196d327fe23a"
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"class_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"class_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67iKJ60z1kRh"
      },
      "source": [
        "# Generating dataset for main project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2AjBlpYwE8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f8583f9d-50fa-492b-8c57-4472c7671ea6"
      },
      "source": [
        "data_size = 4000\n",
        "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(data_size*3)\n",
        "dataset_l = [data[0] for data in dataset]\n",
        "dataset_l[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12000/12000 [00:00<00:00, 17850.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jun 26 2003',\n",
              " '18 sep 1994',\n",
              " '4 january 1983',\n",
              " 'wednesday february 13 1991',\n",
              " 'thursday august 21 2003']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd_VJPgF0Imp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "583e74ed-fbb9-451d-ba84-881335ba88f1"
      },
      "source": [
        "len(dataset_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlQfT0jywT01"
      },
      "source": [
        "num_l = list()\n",
        "for i in range(data_size):\n",
        "  num_l.append(str(random.randint(-10000, 10000)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvlBMHNawhKK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab1e031d-e3ca-42c6-edd6-d196250801a4"
      },
      "source": [
        "emma = gutenberg.words('austen-sense.txt')\n",
        "word_l = list(set(emma))[:data_size]\n",
        "len(word_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nHL12xrxHG-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "161c04a9-7641-4de7-b95e-e94d60e5e76a"
      },
      "source": [
        "emma_sent = gutenberg.sents('melville-moby_dick.txt')\n",
        "sent_l = list(x for x in emma_sent)[:data_size]\n",
        "sent_s = [' '.join(sent) for sent in sent_l]\n",
        "len(sent_s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DchMiqVwput",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3165e1f0-278f-4d5e-ece3-02c9b92519db"
      },
      "source": [
        "date_1 = dataset_l[:4000]\n",
        "date_2 = dataset_l[4000:8000]\n",
        "date_3 = dataset_l[8000:]\n",
        "print(\"Date Sizes: \", len(date_1), len(date_2), len(date_3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date Sizes:  4000 4000 4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRok7f3oxv4s"
      },
      "source": [
        "dataset_dict = {\"Sentences\": sent_s, \"Date_1\":date_1, \"Words\": word_l, \"Date_2\":date_2, \"Numbers\":num_l, \"Date_3\":date_3}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm3GGuT01Fxq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "265f4eb3-68a9-4d69-9b98-6a34a262e9a5"
      },
      "source": [
        "data_df = pd.DataFrame(dataset_dict)\n",
        "data_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "      <th>Date_1</th>\n",
              "      <th>Words</th>\n",
              "      <th>Date_2</th>\n",
              "      <th>Numbers</th>\n",
              "      <th>Date_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ Moby Dick by Herman Melville 1851 ]</td>\n",
              "      <td>jun 26 2003</td>\n",
              "      <td>affectionately</td>\n",
              "      <td>sunday august 31 2008</td>\n",
              "      <td>6141</td>\n",
              "      <td>sunday june 21 1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ETYMOLOGY .</td>\n",
              "      <td>18 sep 1994</td>\n",
              "      <td>Madam</td>\n",
              "      <td>4 nov 1999</td>\n",
              "      <td>-5205</td>\n",
              "      <td>tuesday june 5 2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>( Supplied by a Late Consumptive Usher to a Gr...</td>\n",
              "      <td>4 january 1983</td>\n",
              "      <td>,</td>\n",
              "      <td>15 november 1988</td>\n",
              "      <td>-2748</td>\n",
              "      <td>monday november 19 1984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The pale Usher -- threadbare in coat , heart ,...</td>\n",
              "      <td>wednesday february 13 1991</td>\n",
              "      <td>ornament</td>\n",
              "      <td>thursday march 24 1983</td>\n",
              "      <td>2114</td>\n",
              "      <td>saturday july 15 2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>He was ever dusting his old lexicons and gramm...</td>\n",
              "      <td>thursday august 21 2003</td>\n",
              "      <td>taxed</td>\n",
              "      <td>10 august 1985</td>\n",
              "      <td>5809</td>\n",
              "      <td>wednesday december 3 2014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Sentences  ...                     Date_3\n",
              "0              [ Moby Dick by Herman Melville 1851 ]  ...        sunday june 21 1998\n",
              "1                                        ETYMOLOGY .  ...        tuesday june 5 2007\n",
              "2  ( Supplied by a Late Consumptive Usher to a Gr...  ...    monday november 19 1984\n",
              "3  The pale Usher -- threadbare in coat , heart ,...  ...      saturday july 15 2000\n",
              "4  He was ever dusting his old lexicons and gramm...  ...  wednesday december 3 2014\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cINCVsy519kv"
      },
      "source": [
        "data_df.to_csv(\"dataset.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C8lJ-4v8rLc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "053ebe10-286e-4387-fb84-d5a96955eb2d"
      },
      "source": [
        "X = date_1 + date_2 + date_3 + sent_s + word_l + num_l\n",
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq14_hfU9Iat"
      },
      "source": [
        "with open('tokenizer.pickle', 'wb') as f:\n",
        "  pickle.dump(tok, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}